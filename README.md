# Phase 3: Pipeline Refactoring - âœ… COMPLETED & TESTED

## Overview

Phase 3 implements comprehensive pipeline refactoring with plugin-based notifications, separated concerns, and robust error handling. The architecture now follows a clean separation of concerns with focused, testable components.

## New Architecture

### 1. Plugin-Based Notification System

**Location**: `notifications/`

- **Base Interface**: `notifications/base.py` - Abstract `NotificationProvider` class
- **Providers**: 
  - `notifications/pushover_provider.py` - Pushover notifications
  - `notifications/email_provider.py` - Email notifications  
  - `notifications/gemini_provider.py` - AI analysis via Gemini
- **Manager**: `notifications/manager.py` - Dynamic plugin loading and orchestration

**Features**:
- Standardized `NotificationMessage` format
- Dynamic provider loading based on configuration
- Gemini AI analysis with enhanced messages for other providers
- Comprehensive error handling and logging

### 2. Separated Pipeline Components

**Location**: `pipeline/`

- **Scraper**: `pipeline/scraper.py` - Pure data extraction with retry logic
- **Comparator**: `pipeline/comparator.py` - Change detection using DeepDiff
- **Notifier**: `pipeline/notifier.py` - Alert coordination and delivery
- **Orchestrator**: `pipeline/orchestrator.py` - Main pipeline coordination

**Benefits**:
- Single responsibility principle
- Independent testing capability
- Clear data flow: scraper â†’ comparator â†’ storage â†’ notifier
- Modular error handling

### 3. Comprehensive Error Handling

**Location**: `pipeline/error_handling.py`

**Features**:
- Custom exception hierarchy (`PipelineError`, `ScrapingError`, etc.)
- Retry decorators with configurable backoff strategies
- Circuit breaker pattern for external services
- Centralized error tracking and reporting
- Severity-based logging and notifications

**Strategies**:
- **Fixed Delay**: Constant retry intervals
- **Linear Backoff**: Increasing delays (1s, 2s, 3s...)
- **Exponential Backoff**: Exponential delays (1s, 2s, 4s, 8s...)

### 4. Enhanced Main Pipeline

**Location**: `main.py` (refactored), `pipeline/orchestrator.py`

**Improvements**:
- Clean orchestration with comprehensive error handling
- Fallback mechanisms for each component
- Detailed status reporting and logging
- Graceful failure handling with notifications

## Structured Diff Logging

The system now includes comprehensive logging of grade changes and raw diffs for analysis and fine-tuning:

### Log Files
- **`logs/grade_changes.log`** - Structured change tracking (JSON format)
- **`logs/raw_diffs.log`** - Debug-level raw diff data (when enabled)

### Configuration
```toml
[logging]
enable_change_logging = true          # Production ready
enable_raw_diff_logging = false       # Debug only - can generate large files
change_log_retention_days = 90        # Long-term change history
raw_diff_log_retention_days = 7       # Short-term debug data
```

### Change Log Format
Each change detection creates a structured JSON entry:
```json
{
  "timestamp": "2025-09-15T20:09:22.754633",
  "change_type": "update",
  "summary": "2 value(s) changed, 1 list item(s) added",
  "formatted_message": "Grade changes detected: 2 value(s) changed...",
  "notification_results": {"pushover": true, "email": true, "gemini": false},
  "change_count": 2,
  "priority": "normal",
  "comparison_files": ["data_20250913.json", "data_20250915.json"],
  "metadata": {
    "has_grade_changes": true,
    "has_new_assignments": false,
    "has_removed_items": false
  }
}
```

### Features
- **Structured Format**: JSON entries for easy parsing and analysis
- **Notification Tracking**: Per-provider success/failure results
- **Change Metadata**: Classification of change types for prioritization
- **Automatic Cleanup**: Configurable retention periods prevent disk bloat
- **Debug Mode**: Optional raw DeepDiff output for troubleshooting

### Testing
```bash
python test_diff_logging.py
```

## Configuration

The system uses the existing hybrid TOML + .env configuration approach with enhancements for notification providers:

```python
# Notification configuration is automatically built from:
# - config.credentials.pushover_token/pushover_userkey
# - config.credentials.gemini_key  
# - config.notifications.email_enabled
```

## Usage

### Standard Operation
```bash
python main.py
```

### Testing the Pipeline
```bash
python test_pipeline.py
```

### Component Testing
```python
from pipeline.orchestrator import GradePipeline

pipeline = GradePipeline()
status = pipeline.get_pipeline_status()
test_results = pipeline.test_pipeline_components()
```

## Error Handling Examples

### Retry with Backoff
```python
@retry_with_backoff(max_retries=3, strategy=RetryStrategy.EXPONENTIAL)
def risky_operation():
    # Operation that might fail
    pass
```

### Custom Error Handling
```python
try:
    scrape_data()
except Exception as e:
    handle_scraping_error(e, {"operation": "scrape_grades"})
```

### Circuit Breaker
```python
circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=300)
result = circuit_breaker.call(external_service_call)
```

## Notification System

### Sending Notifications
```python
from notifications.manager import NotificationManager
from notifications.base import NotificationMessage

message = NotificationMessage(
    title="Grade Changes",
    content="New grades detected",
    priority="normal",
    metadata={"changes": change_data}
)

results = manager.send_notification(message)
```

### Provider Configuration
Providers are automatically loaded based on available credentials:

- **Pushover**: Requires `pushover_token` and `pushover_userkey`
- **Email**: Requires email settings and `email_enabled=true`
- **Gemini**: Requires `gemini_key`

## Migration Notes

### Backward Compatibility
- Old `main.py` backed up as `main_old.py`
- Original notification modules preserved but replaced with plugin versions
- All data storage mechanisms unchanged
- Existing configuration files work without modification

### New Files Created
```
notifications/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py
â”œâ”€â”€ pushover_provider.py
â”œâ”€â”€ email_provider.py
â”œâ”€â”€ gemini_provider.py
â””â”€â”€ manager.py

pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ scraper.py
â”œâ”€â”€ comparator.py
â”œâ”€â”€ notifier.py
â”œâ”€â”€ orchestrator.py
â””â”€â”€ error_handling.py

shared/
â”œâ”€â”€ config.py (enhanced)
â””â”€â”€ diff_logger.py (new)

logs/
â”œâ”€â”€ grade_changes.log (auto-generated)
â””â”€â”€ raw_diffs.log (auto-generated, configurable)

test_pipeline.py
test_diff_logging.py (new)
PHASE3_README.md
```

## Testing

The `test_pipeline.py` script validates:

1. Configuration loading
2. Component initialization
3. Notification provider availability
4. Pipeline integration
5. Error handling system
6. End-to-end workflow (without actual scraping)

The `test_diff_logging.py` script demonstrates:

1. Structured change logging functionality
2. JSON log format and content
3. Notification result tracking
4. Change metadata classification
5. Raw diff logging (when enabled)

## Benefits Achieved

1. **Modularity**: Clear separation of concerns
2. **Testability**: Each component can be tested independently
3. **Reliability**: Comprehensive error handling and retry logic
4. **Extensibility**: Easy to add new notification providers
5. **Maintainability**: Focused modules with single responsibilities
6. **Observability**: Enhanced logging and error tracking
7. **Analytics**: Structured diff logging for data-driven optimization
8. **Debugging**: Comprehensive change tracking with notification result correlation

## âœ… Validation Results

**Test Status**: **7/7 TESTS PASSED** ðŸŽ‰
- âœ… Configuration Loading
- âœ… Scraper Component  
- âœ… Comparator Component
- âœ… Notification Providers (Pushover, Email, Gemini)
- âœ… Pipeline Status & Integration
- âœ… Error Handling System
- âœ… End-to-End Integration

## Next Steps

1. âœ… ~~Run `python test_pipeline.py` to validate the implementation~~ **COMPLETED**
2. âœ… ~~**Restore conditional storage logic** - Only save when data changes~~ **COMPLETED**
3. Ready to test the full pipeline with `python main.py`
4. Monitor logs for any issues during production operation
5. Consider removing old backup files after successful operation validation

## âœ… **PHASE 3 COMPLETE**

The Phase 3 refactoring maintains all existing functionality while providing a robust, extensible foundation for future enhancements. All architectural goals have been achieved and validated through comprehensive testing.

**All Issues Resolved**: Conditional storage logic has been restored and enhanced - the system now only saves data when changes are detected, with configurable behavior and comprehensive logging.

### **âœ… Implementation Validated**
- **Test Result**: Successfully skips saves when no changes detected
- **Storage Optimization**: No unnecessary DynamoDB writes or local files
- **Logging**: Clear decision tracking for all save operations  
- **Configuration**: Fully configurable with fail-safe options